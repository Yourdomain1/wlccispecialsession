<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Uncertainty, Explainability, and Trustworthiness in Computational Intelligence for Healthcare</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: 20px auto;
            padding: 20px;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        h1, h2, h3 {
            color: #004085;
            border-bottom: 2px solid #004085;
            padding-bottom: 5px;
            margin-top: 20px;
        }
        h1 {
            text-align: center;
        }
        .section {
            margin-bottom: 30px;
        }
        .organizer {
            margin-bottom: 15px;
        }
        .organizer h3 {
            margin-top: 0;
            border-bottom: none;
            color: #0056b3;
        }
        .organizer p {
            margin: 5px 0;
        }
        .contact {
            font-weight: bold;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        ul {
            list-style-type: disc;
            padding-left: 20px;
        }
        li {
            margin-bottom: 10px;
        }
        .note {
            font-style: italic;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Uncertainty, Explainability, and Trustworthiness in Computational Intelligence for Healthcare</h1>
        <p style="text-align: center;">A Special Session at the IEEE World Congress on Computational Intelligence (WCCI) 2026</p>

        <div class="section">
            <h2>Abstract</h2>
            <p>The successful integration of AI into high-stakes clinical applications hinges not only on algorithmic accuracy but also on the system's trustworthiness and interpretability. This special session will serve as an interdisciplinary forum to explore the latest advancements in computational intelligence that address these critical needs across the healthcare continuum. Building on the core expertise of the organizers, the session will focus on applying state-of-the-art deep learning models to diverse medical data modalities, with a strong emphasis on <strong>uncertainty quantification, self-supervised learning, and explainable AI (XAI).</strong></p>
            <p>We will welcome contributions that tackle fundamental challenges in medical data analysis, such as developing efficient deep models (CNNs, ViTs), integrating uncertainty modeling techniques, and leveraging abundant unlabeled and synthetic data through unsupervised and self-supervised paradigms to enhance model robustness. A central theme will be the investigation of XAI methods, including saliency and class activation maps, to provide comprehensive, actionable insights to clinicians. The session is directly relevant to IJCNN, FUZZ-IEEE, and IEEE CEC as it addresses core computational intelligence challenges—robustness, explainability, and trustworthiness—within the high-impact domain of healthcare. The ultimate goal is to foster a dialogue that bridges algorithmic innovation with real-world clinical validation and user-centric design, moving beyond pure performance metrics to a holistic framework for responsible AI deployment.</p>
        </div>

        <div class="section">
            <h2>Organisers</h2>
            <div class="organizer">
                <h3>Pr. Imen Jdey</h3>
                <p><strong>Affiliation:</strong> University of Kairouan, Tunisia</p>
                <p><strong>Email
