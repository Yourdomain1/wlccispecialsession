<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Special Session Proposal</title>
    <style>
        body {
            font-family: sans-serif;
            line-height: 1.6;
            margin: 2em;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }
        h1, h2 {
            color: #333;
        }
        ul {
            list-style-type: disc;
            margin-left: 20px;
        }
        .organizers, .contact {
            margin-bottom: 1em;
        }
    </style>
</head>
<body>

    <h1>Special Session Proposal:</h1>
    <h2>Explainability and Interpretability in Computational Intelligence for Diverse Data</h2>
    <h3>A Special Session at the IEEE World Congress on Computational Intelligence (WCCI) 2026</h3>

    <div class="organizers">
        <p><strong>Organizers:</strong> [M. Tanveer, Indian Institute of Technology Indore, India, m.tanveer@ieee.org], [Imen Jdey, REGIM Lab, Sfax University, imen.jdey@ieee.org], [[Fadoua Drira, REGIM Lab, Sfax University, Email.] [Rahma Fourati, REGIM Lab, Sfax University,rahma.fourati@ieee.org],</p>
    </div>

    <div class="contact">
        <p><strong>Primary Contact:</strong> [imen.jdey@ieee.org]</p>
    </div>

    <hr>

    <h2>Abstract</h2>
    <p>The widespread adoption of computational intelligence across various high-stakes domains, from computer vision to signal processing and beyond, is heavily reliant on our ability to understand and trust the decisions made by these complex models. This special session will serve as a focused, interdisciplinary forum to explore the latest advancements in eXplainable and interpretable AI (XAI). Our specific emphasis will be on novel methods and applications for diverse data modalities: images, audio (signal), array data, and multimodal data. We will welcome contributions that tackle fundamental challenges in making AI models transparent and trustworthy, such as developing novel XAI techniques tailored to different data types, evaluating the effectiveness of these methods from a human-centric perspective, and bridging the gap between algorithmic explanations and real-world comprehension. The session is directly relevant to IJCNN, FUZZ-IEEE, and IEEE CEC as it addresses core computational intelligence challenges—robustness, explainability, and trustworthiness—within the context of various data types. The ultimate goal is to foster a dialogue that moves beyond pure performance metrics to a holistic framework for responsible and transparent AI deployment.</p>

    <hr>

    <h2>Topics of Interest</h2>
    <p>Topics of interest include, but are not limited to:</p>
    <ul>
        <li>Explainable and Transparent AI (XAI) for Image and Audio Analysis</li>
        <li>Interpretable Deep Learning Models for Array and Tabular Data</li>
        <li>Multimodal Explainability: Fusing Explanations Across Different Data Types</li>
        <li>Novel Visualization Techniques for Model Interpretations</li>
        <li>Evaluating the Human-in-the-Loop Aspects of XAI</li>
        <li>Algorithmic Audits and Trustworthiness of AI Systems</li>
        <li>Mitigating Bias in Explanations and Ensuring Fairness</li>
        <li>Causality and Counterfactual Explanations for Different Data Modalities</li>
        <li>XAI in Signal Processing and Time-Series Analysis</li>
        <li>Applying XAI to Fuzzy Systems and Evolutionary Computation</li>
        <li>Benchmark Datasets and Metrics for Evaluating Explanations</li>
    </ul>

    <hr>

    <h2>Relevance to WCCI</h2>
    <p>This special session aligns directly with the themes of the WCCI's three flagship conferences:</p>
    <ul>
        <li><strong>IJCNN (International Joint Conference on Neural Networks):</strong> The session will showcase the latest advancements in XAI for deep neural networks, including CNNs, ViTs, and other architectures, which are central to modern computer vision and signal processing.</li>
        <li><strong>FUZZ-IEEE (IEEE International Conference on Fuzzy Systems):</strong> We will explore how fuzzy logic and fuzzy systems can be used to develop intrinsically interpretable models and to provide human-understandable explanations for black-box models.</li>
        <li><strong>IEEE CEC (IEEE Congress on Evolutionary Computation):</strong> The session will address the application of evolutionary algorithms to optimize and generate more interpretable models, as well as the use of XAI to understand the decision-making process of complex evolutionary systems.</li>
    </ul>

    <hr>

    <h2>Expected Benefit</h2>
    <p>The proposed special session will benefit the WCCI community by creating a dedicated venue for this rapidly growing and critical field. It will attract high-quality submissions from researchers across different disciplines and will foster new collaborations, bridging the gap between theoretical XAI research and its practical application to diverse data modalities. We aim to contribute to the WCCI's mission of promoting computational intelligence research that is not only powerful but also transparent, trustworthy, and responsible.</p>

    <hr>

    <h2>Call for Papers</h2>
    <p>We welcome submissions on the topics listed above. All papers will be subject to the same rigorous peer-review process as regular WCCI 2026 submissions. Authors are encouraged to submit early. For submission details and deadlines, please refer to the official WCCI 2026 conference website.</p>

</body>
</html>
