<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Special Session Proposal</title>
    <style>
        body {
            font-family: sans-serif;
            line-height: 1.6;
            margin: 2em;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }
        h1, h2 {
            color: #333;
        }
        ul {
            list-style-type: disc;
            margin-left: 20px;
        }
        .organizers, .contact, .biography, .additional-activities, .papers {
            margin-bottom: 1em;
        }
    </style>
</head>
<body>

    <h1>Special Session Proposal:</h1>
    <h2>Explainability and Interpretability in Computational Intelligence for Diverse Data</h2>
    <h3>A Special Session at the IEEE World Congress on Computational Intelligence (WCCI) 2026</h3>

    <div class="organizers">
        <p><strong>Organizers:</strong> [M. Tanveer, Indian Institute of Technology Indore, India, m.tanveer@ieee.org], [Imen Jdey, REGIM Lab, Sfax University, imen.jdey@ieee.org], [Fadoua Drira, REGIM Lab, Sfax University, Email.], [Rahma Fourati, REGIM Lab, Sfax University, rahma.fourati@ieee.org], [Dirck van der Laan, University of Maastricht, The Netherlands, d.vdlaan@maastrichtuniversity.nl]</p>
    </div>

    <div class="contact">
        <p><strong>Primary Contact:</strong> [imen.jdey@ieee.org]</p>
    </div>

    <hr>

    <div class="biography">
        <h3>Organizer Biographies</h3>
        <h4>M. Tanveer</h4>
        <p>M. Tanveer is a Professor and Ramanujan Fellow at the Department of Mathematics of the Indian Institute of Technology Indore. His research spans a wide range of topics, including support vector machines, optimization, machine learning, and deep learning, with applications to biomedical signal processing and Alzheimer's disease. His work focuses on creating robust and trustworthy AI models, which is directly relevant to the session's emphasis on eXplainable AI (XAI).</p>
        
        <h4>Imen Jdey</h4>
        <p>Imen Jdey is a researcher at REGIM Lab, Sfax University. Her research interests are centered on machine learning and signal processing, with a particular focus on the development of eXplainable AI (XAI) methods. She is dedicated to creating transparent and trustworthy models for a variety of data types, including audio and multimodal data, to ensure that AI systems are not only accurate but also understandable and reliable.</p>

        <h4>Fadoua Drira</h4>
        <p>Fadoua Drira is an Associate Professor in the Department of Computer Science at ENIS University of Sfax and the head of the Research Groups on Intelligent Machines Laboratory (ReGIM-Lab). Her research interests include computational intelligence, image processing, and computer vision. Her work, including a recent paper on explainable skin cancer diagnosis using Vision Transformers, demonstrates her commitment to applying explainable AI techniques to real-world medical and vision-based challenges.</p>

        <h4>Rahma Fourati</h4>
        <p>Rahma Fourati is a researcher at REGIM Lab, Sfax University. Her research interests are in neural networks, generative models, and EEG signal analysis, with a focus on applications such as epileptic seizure prediction. She has worked on topics related to model compression and efficient neural networks, which are crucial for the practical deployment of AI systems. Her interest in EEG signals and other biomedical data aligns perfectly with the session's focus on XAI for diverse data modalities.</p>
       
        <h4>Dirck van der Laan</h4>
        <p>Dirck van der Laan is a research fellow at the Department of Advanced Computing Sciences at Maastricht University. His work focuses on the intersection of AI, cognitive science, and human-computer interaction, with a strong emphasis on the psychological and user-centric aspects of explainability. His research explores how different forms of explanations—from visual heatmaps to counterfactual examples—are perceived and utilized by end-users, ensuring that XAI solutions are not just technically sound but also effectively understood and trusted by humans.</p>
    </div>

    <hr>

    <h2>Abstract</h2>
    <p>The widespread adoption of computational intelligence across various high-stakes domains, from computer vision to signal processing and beyond, is heavily reliant on our ability to understand and trust the decisions made by these complex models. This special session will serve as a focused, interdisciplinary forum to explore the latest advancements in eXplainable and interpretable AI (XAI). Our specific emphasis will be on novel methods and applications for diverse data modalities: images, audio (signal), array data, and multimodal data. We will welcome contributions that tackle fundamental challenges in making AI models transparent and trustworthy, such as developing novel XAI techniques tailored to different data types, evaluating the effectiveness of these methods from a human-centric perspective, and bridging the gap between algorithmic explanations and real-world comprehension. The session is directly relevant to IJCNN, FUZZ-IEEE, and IEEE CEC as it addresses core computational intelligence challenges—robustness, explainability, and trustworthiness—within the context of various data types. The ultimate goal is to foster a dialogue that moves beyond pure performance metrics to a holistic framework for responsible and transparent AI deployment.</p>

    <hr>

    <h2>Topics of Interest</h2>
    <p>Topics of interest include, but are not limited to:</p>
    <ul>
        <li>Explainable and Transparent AI (XAI) for Image and Audio Analysis</li>
        <li>Interpretable Deep Learning Models for Array and Tabular Data</li>
        <li>Multimodal Explainability: Fusing Explanations Across Different Data Types</li>
        <li>Novel Visualization Techniques for Model Interpretations</li>
        <li>Evaluating the Human-in-the-Loop Aspects of XAI</li>
        <li>Algorithmic Audits and Trustworthiness of AI Systems</li>
        <li>Mitigating Bias in Explanations and Ensuring Fairness</li>
        <li>Causality and Counterfactual Explanations for Different Data Modalities</li>
        <li>XAI in Signal Processing and Time-Series Analysis</li>
        <li>Applying XAI to Fuzzy Systems and Evolutionary Computation</li>
        <li>Benchmark Datasets and Metrics for Evaluating Explanations</li>
    </ul>

    <hr>

    <h2>Relevance to WCCI</h2>
    <p>This special session aligns directly with the themes of the WCCI's three flagship conferences:</p>
    <ul>
        <li><strong>IJCNN (International Joint Conference on Neural Networks):</strong> The session will showcase the latest advancements in XAI for deep neural networks, including CNNs, ViTs, and other architectures, which are central to modern computer vision and signal processing.</li>
        <li><strong>FUZZ-IEEE (IEEE International Conference on Fuzzy Systems):</strong> We will explore how fuzzy logic and fuzzy systems can be used to develop intrinsically interpretable models and to provide human-understandable explanations for black-box models.</li>
        <li><strong>IEEE CEC (IEEE Congress on Evolutionary Computation):</strong> The session will address the application of evolutionary algorithms to optimize and generate more interpretable models, as well as the use of XAI to understand the decision-making process of complex evolutionary systems.</li>
    </ul>

    <hr>

    <div class="papers">
        <h3>Relevant Papers</h3>
        <p>The following papers are highly relevant to the topics covered in this special session:</p>
        <ul>
            <li><strong>"XAI-based Data Visualization in Multimodal Medical Data"</strong> by Sahil Sharma, Muskaan Singh, Liam McDaid, Saugat Bhattacharyya. This paper directly addresses the challenges of explaining models that use diverse medical data, including imaging, sensor, and omics data.</li>
            <li><strong>"Multimodal Explainable Artificial Intelligence: A Comprehensive Review of Methodological Advances and Future Research Directions"</strong> by N. Rodis et al. This review provides a systematic analysis of Multimodal XAI (MXAI) methods, which is a core theme of the special session.</li>
            <li><strong>"A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future"</strong> by Xing Su et al. This paper categorizes MXAI methods across different eras of AI development, offering a valuable overview for the community.</li>
            <li><strong>"Audio Explainable Artificial Intelligence: A Review"</strong> by S. Kumar and M. S. Obaidat. This work focuses specifically on XAI methods tailored for audio-based tasks, which is a key topic in the proposal.</li>
            <li><strong>"Explainable Artificial Intelligence in Biomedical Image Analysis: A Comprehensive Survey"</strong> by G. Singh et al. This survey reviews XAI methods applied to biomedical images, a crucial data modality for the special session.</li>
        </ul>
    </div>

    <hr>

    <h2>Expected Benefit</h2>
    <p>The proposed special session will benefit the WCCI community by creating a dedicated venue for this rapidly growing and critical field. It will attract high-quality submissions from researchers across different disciplines and will foster new collaborations, bridging the gap between theoretical XAI research and its practical application to diverse data modalities. We aim to contribute to the WCCI's mission of promoting computational intelligence research that is not only powerful but also transparent, trustworthy, and responsible.</p>

    <hr>

    <div class="additional-activities">
        <h3>Additional Activities</h3>
        <p>To enhance participant engagement and foster deeper dialogue, this special session will incorporate an <strong>Open Discussion Slot (ODS)</strong>. This activity is designed to go beyond traditional paper presentations and create a collaborative environment for attendees.</p>

        <h4>Open Discussion Slot (ODS)</h4>
        <ul>
            <li><strong>Type and Format:</strong> This will be a facilitated, interactive discussion. Following the paper presentations, a dedicated 30-minute block will be allocated for this activity. The session chairs will serve as facilitators, guiding the discussion.</li>
            <li><strong>Time Requirements:</strong> A <strong>30-minute slot</strong> will be reserved at the end of the special session, following all scheduled paper presentations.</li>
            <li><strong>Expected Benefit:</strong> The ODS will serve as a dynamic forum for attendees to share insights, raise critical questions, and brainstorm solutions collectively. It will allow for a free-flowing exchange of ideas that may not fit into the Q&A segment of individual paper presentations. This format is intended to bridge the gap between theoretical research and practical challenges, encouraging new collaborations and helping to identify future research directions in XAI for diverse data modalities.</li>
            <li><strong>Facilitators:</strong> The session organizers, M. Tanveer, Imen Jdey, Fadoua Drira, Rahma Fourati, and Dirck van der Laan, will co-facilitate the discussion, ensuring a productive and inclusive exchange of ideas.</li>
        </ul>
    </div>

    <hr>

    <h2>Call for Papers</h2>
    <p>We welcome submissions on the topics listed above. All papers will be subject to the same rigorous peer-review process as regular WCCI 2026 submissions. Authors are encouraged to submit early. For submission details and deadlines, please refer to the official WCCI 2026 conference website.</p>

</body>
</html>
