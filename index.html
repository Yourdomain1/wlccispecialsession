<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Uncertainty, Explainability, and Trustworthiness in Computational Intelligence for Healthcare</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: 20px auto;
            padding: 20px;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        h1, h2, h3 {
            color: #004085;
            border-bottom: 2px solid #004085;
            padding-bottom: 5px;
            margin-top: 20px;
        }
        h1 {
            text-align: center;
        }
        .section {
            margin-bottom: 30px;
        }
        .organizer, .speaker {
            margin-bottom: 15px;
        }
        .organizer h3, .speaker h3 {
            margin-top: 0;
            border-bottom: none;
            color: #0056b3;
        }
        .organizer p, .speaker p {
            margin: 5px 0;
        }
        .contact {
            font-weight: bold;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        ul {
            list-style-type: disc;
            padding-left: 20px;
        }
        li {
            margin-bottom: 10px;
        }
        .note {
            font-style: italic;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Uncertainty, Explainability, and Trustworthiness in Computational Intelligence for Healthcare</h1>
        <p style="text-align: center;">A Special Session at the IEEE World Congress on Computational Intelligence (WCCI) 2026</p>

        <div class="section">
            <h2>Abstract</h2>
            <p>The successful integration of AI into high-stakes clinical applications hinges not only on algorithmic accuracy but also on the system's trustworthiness and interpretability. This special session will serve as an interdisciplinary forum to explore the latest advancements in computational intelligence that address these critical needs across the healthcare continuum. Building on the core expertise of the organizers, the session will focus on applying state-of-the-art deep learning models to diverse medical data modalities, with a strong emphasis on <strong>uncertainty quantification, self-supervised learning, and explainable AI (XAI).</strong></p>
            <p>We will welcome contributions that tackle fundamental challenges in medical data analysis, such as developing efficient deep models (CNNs, ViTs), integrating uncertainty modeling techniques, and leveraging abundant unlabeled and synthetic data through unsupervised and self-supervised paradigms to enhance model robustness. A central theme will be the investigation of XAI methods, including saliency and class activation maps, to provide comprehensive, actionable insights to clinicians. The session is directly relevant to IJCNN, FUZZ-IEEE, and IEEE CEC as it addresses core computational intelligence challenges—robustness, explainability, and trustworthiness—within the high-impact domain of healthcare. The ultimate goal is to foster a dialogue that bridges algorithmic innovation with real-world clinical validation and user-centric design, moving beyond pure performance metrics to a holistic framework for responsible AI deployment.</p>
        </div>

        <div class="section">
            <h2>Organisers</h2>
            <div class="organizer">
                <h3>Pr. Imen Jdey</h3>
                <p><strong>Affiliation:</strong> University of Kairouan, Tunisia</p>
                <p><strong>Email:</strong> [Email Address]</p>
                <p><strong>Website:</strong> <a href="#">[Website/ResearchGate Profile]</a></p>
                <p class="note">Short Bio: An Assistant Professor with a strong research focus on deep learning for handwriting and medical data analysis. Her recent work includes significant contributions to malaria detection, breast cancer diagnosis, and the application of privacy-preserving techniques like federated learning and blockchain in healthcare.</p>
            </div>
            <div class="organizer">
                <h3>Pr. M. Tanveer</h3>
                <p><strong>Affiliation:</strong> Indian Institute of Technology Indore, India</p>
                <p><strong>Email:</strong> [Email Address]</p>
                <p><strong>Website:</strong> <a href="#">[Website/ResearchGate Profile]</a></p>
                <p class="note">Short Bio: A renowned Professor and Ramanujan Fellow with extensive expertise in support vector machines, fuzzy systems, and deep learning. His research applies these methods to biomedical data, with a specific emphasis on the diagnosis of neurological disorders like Alzheimer's disease and dementia. He has a history of organizing successful special sessions at top-tier conferences.</p>
            </div>
            <div class="organizer">
                <h3>Pr. Fadoua Drira</h3>
                <p><strong>Affiliation:</strong> University of Sfax, Tunisia</p>
                <p><strong>Email:</strong> [Email Address]</p>
                <p><strong>Website:</strong> <a href="#">[Website/ResearchGate Profile]</a></p>
                <p class="note">Short Bio: An Associate Professor and Head of the Research Groups on Intelligent Machines (ReGIM-Lab). Her research interests are centered on image processing and computer vision, with a particular focus on medical image analysis, segmentation, and secure medical data sharing.</p>
            </div>
        </div>

        <div class="section">
            <h2>Primary Contact</h2>
            <p class="contact">For any inquiries, please contact: imen.jdey@ieee.org</p>
        </div>

        <div class="section">
            <h2>Topics of Interest</h2>
            <p>Topics of interest include, but are not limited to:</p>
            <ul>
                <li>Uncertainty-Aware Deep Learning Models for Medical Diagnosis and Prognosis</li>
                <li>Self-Supervised and Unsupervised Learning for Medical Image and Sensor Data</li>
                <li>Explainable and Transparent AI (XAI) for Clinical Decision-Making</li>
                <li>Mitigating Bias and Ensuring Fairness in Healthcare AI Systems</li>
                <li>Privacy-Preserving Techniques (Federated Learning, Blockchain) in Medical Data Analysis</li>
                <li>AI for Public Health, Epidemiology, and Resource Allocation</li>
                <li>Human-in-the-Loop Systems and Shared Decision-Making in Clinical Practice</li>
                <li>Ethical and Algorithmic Audits of AI Systems for Clinical Use</li>
                <li>Multiscale Modeling of Biological Systems using Computational Intelligence</li>
            </ul>
        </div>

        <div class="section">
            <h2>Committed Papers (Optional but highly recommended)</h2>
            <p>The following papers are already committed to being submitted to this special session:</p>
            <ul>
                <li>
                    <strong>Title:</strong> Uncertainty-Aware Deep Models for Medical Diagnosis using Evidential Deep Learning (EDL)<br>
                    <strong>Authors:</strong> [List of Authors]<br>
                    <p class="note">This paper presents a novel approach for general medical image analysis that integrates evidential deep learning (EDL) to provide clinicians with quantifiable measures of model confidence and uncertainty. The work focuses on improving the trustworthiness of AI predictions for critical diagnostic tasks.</p>
                </li>
                <li>
                    <strong>Title:</strong> A Self-Supervised Learning Framework for Robust Medical Image Analysis from Unlabeled Data<br>
                    <strong>Authors:</strong> [List of Authors]<br>
                    <p class="note">We propose a self-supervised learning paradigm that leverages large volumes of unlabeled medical images to significantly improve the accuracy and robustness of deep learning models. This approach aims to reduce the dependency on extensive, manually annotated datasets and enhance domain adaptation to new clinical environments.</p>
                </li>
                <li>
                    <strong>Title:</strong> Visual and Attribute-Based Explainable AI for Clinical Decision Support in Oral Surgery<br>
                    <strong>Authors:</strong> [List of Authors]<br>
                    <p class="note">This work investigates ensemble explainable AI (XAI) techniques, including saliency maps and attribute classifiers, to provide clinicians with comprehensive visual and text-based explanations for AI-driven diagnoses. The goal is to enhance the transparency and acceptance of these systems in clinical practice.</p>
                </li>
                <li>
                    <strong>Title:</strong> A Comparative Study of CNN and Vision Transformer Architectures for General Medical Image Classification<br>
                    <strong>Authors:</strong> [List of Authors]<br>
                    <p class="note">We present a comparative analysis of convolutional neural networks (CNNs) and Vision Transformers (ViTs) for crucial medical image classification tasks. The study evaluates the performance, efficiency, and robustness of each architecture to identify the most effective models for clinical application.</p>
                </li>
                <li>
                    <strong>Title:</strong> A Fuzzy-Based Support Vector Machine for Accurate Alzheimer's Disease Classification from MRI<br>
                    <strong>Authors:</strong> M. Tanveer, [Co-authors]<br>
                    <p class="note">We introduce a new fuzzy support vector machine (FSVM) model designed to improve the classification accuracy of Alzheimer's disease by effectively handling noisy and class-imbalanced neuroimaging data, a key challenge in the field.</p>
                </li>
            </ul>
        </div>

        <div class="section">
            <h2>Invited Speakers</h2>
            <div class="speaker">
                <h3>Pr. Drock Brand</h3>
                <p><strong>Affiliation:</strong> [Affiliation]</p>
                <p class="note">Bio: A Professor specializing in AI ethics and data governance. His/Her expertise will be invaluable in examining the ethical frameworks and societal implications of AI, particularly in a high-stakes domain like healthcare.</p>
            </div>
            <div class="speaker">
                <h3>Pr. Dimitrios I. Fotiadis</h3>
                <p><strong>Affiliation:</strong> University of Ioannina, Greece</p>
                <p class="note">Bio: A Professor of Biomedical Engineering and Director of the Unit of Medical Technology and Intelligent Information Systems. His research is at the forefront of multiscale modeling, intelligent wearable devices for automated diagnosis, big medical data processing, and AI trustworthiness frameworks. He is the Editor-in-Chief of the IEEE Journal of Biomedical and Health Informatics.</p>
            </div>
        </div>
        
        <div class="section">
            <h2>Call for Papers</h2>
            <p>We welcome submissions on the topics listed above. All papers will be subject to the same rigorous peer-review process as regular WCCI 2026 submissions. Authors are encouraged to submit early. For submission details and deadlines, please refer to the official <a href="[Link to WCCI 2026 official submission page]">WCCI 2026 conference website</a>.</p>
        </div>

    </div>
</body>
</html>
